{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts, Output Parsers, Chain\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Models\n",
    "   * Prompts\n",
    "   * Output parsers\n",
    "   * Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.14.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('secret/api_key', 'r') as file:\n",
    "    api_key = file.read().strip()  # read the file content and remove any leading or trailing whitespace\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_completion(system_prompt, prompt, model=\"gpt-3.5-turbo\"):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Abbraccia il cambiamento, coltiva la leadership, diventa il Manager della tua vita!\"\n"
     ]
    }
   ],
   "source": [
    "from utils import print_ww\n",
    "\n",
    "system_prompt = \"Sei un life coach molto bravo con i discorsi motivazionali. Rispondi con uno slogan\"\n",
    "prompt = \"Come faccio a diventare Manager?\"\n",
    "\n",
    "print_ww(get_completion(system_prompt, prompt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "Let's try how we can do the same using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.14)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.41 (from langchain)\n",
      "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.27)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.41->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\f.micco\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.15-py3-none-any.whl (814 kB)\n",
      "   ---------------------------------------- 0.0/814.5 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 225.3/814.5 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 696.3/814.5 kB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  809.0/814.5 kB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 814.5/814.5 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.7/1.9 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.41-py3-none-any.whl (278 kB)\n",
      "   ---------------------------------------- 0.0/278.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  276.5/278.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 278.4/278.4 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.40\n",
      "    Uninstalling langchain-core-0.1.40:\n",
      "      Successfully uninstalled langchain-core-0.1.40\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.31\n",
      "    Uninstalling langchain-community-0.0.31:\n",
      "      Successfully uninstalled langchain-community-0.0.31\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.14\n",
      "    Uninstalling langchain-0.1.14:\n",
      "      Successfully uninstalled langchain-0.1.14\n",
      "Successfully installed langchain-0.1.15 langchain-community-0.0.32 langchain-core-0.1.41\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.micco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000028B161B50A0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000028B161B61B0>, temperature=0.0, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Tradurre il testo\n",
    "che è delimitato da triplo backtick\n",
    "in uno stile che è {style}.\n",
    "testo: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Tradurre il testo\\nche è delimitato da triplo backtick\\nin uno stile che è {style}.\\ntesto: ```{text}```\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"Italiano \\\n",
    "con un tono calmo e rispettoso\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, sono incazzato nero perchè il coperchio del mio frullatore è volato via ed ha schizzato le pareti\n",
    "della mia cucina con lo smoothie! E per rendere le cose peggiori, la garanzia non copre il costo\n",
    "della pulizia della mia cucina. Mi devi aiutare porca miseria!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Tradurre il testo\\nche è delimitato da triplo backtick\\nin uno stile che è Italiano con un\n",
      "tono calmo e rispettoso\\n.\\ntesto: ```\\nArrr, sono incazzato nero perchè il coperchio del mio\n",
      "frullatore è volato via ed ha schizzato le pareti\\ndella mia cucina con lo smoothie! E per rendere\n",
      "le cose peggiori, la garanzia non copre il costo\\ndella pulizia della mia cucina. Mi devi aiutare\n",
      "porca miseria!\\n```\\n'\n"
     ]
    }
   ],
   "source": [
    "print_ww(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.micco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi dispiace sentire che hai avuto questo inconveniente con il tuo frullatore. Capisco quanto possa\n",
      "essere frustrante dover pulire la cucina a causa di uno spiacevole incidente. Vorrei poterti aiutare\n",
      "a risolvere la situazione nel modo migliore possibile. Fammi sapere come posso essere d'aiuto.\n"
     ]
    }
   ],
   "source": [
    "print_ww(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"\n",
    "Ehi cliente,\n",
    "la garanzia non copre le spese di pulizia per la tua cucina perché \n",
    "è colpa tua se hai usato erroneamente il frullatore dimenticando \n",
    "di mettere il coperchio prima di avviarlo.\n",
    "Sfortuna! Arrivederci!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "dal tono educato \\\n",
    "ed in Spagnolo\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tradurre il testo\n",
      "che è delimitato da triplo backtick\n",
      "in uno stile che è dal tono educato ed in Spagnolo.\n",
      "testo: ```\n",
      "Ehi cliente,\n",
      "la garanzia non copre le spese di pulizia per la tua cucina perché\n",
      "è colpa tua se hai usato erroneamente il frullatore dimenticando\n",
      "di mettere il coperchio prima di avviarlo.\n",
      "Sfortuna! Arrivederci!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print_ww(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola estimado cliente,\n",
      "\n",
      "Lamentamos informarle que la garantía no cubre los gastos de limpieza de su cocina, ya que es su\n",
      "responsabilidad si ha utilizado incorrectamente la licuadora olvidando colocar la tapa antes de\n",
      "encenderla.\n",
      "\n",
      "¡Qué mala suerte! ¡Hasta luego!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print_ww(service_response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'abbastanza conveniente!'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"abbastanza conveniente!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "Questo soffiatore di foglie è davvero sorprendente. Ha quattro impostazioni: soffiatore per candele,\n",
    "brezza leggera, città ventosa e tornado. È arrivato in due giorni, proprio in tempo per il regalo di\n",
    "anniversario di mia moglie. Penso che mia moglie lo abbia apprezzato così tanto che è rimasta \n",
    "senza parole. Finora sono stato l'unico a usarlo, e lo uso ogni altro mattino per togliere le \n",
    "foglie dal nostro prato. È leggermente più costoso degli altri soffiatori di foglie sul mercato, \n",
    "ma penso che valga la pena per le funzionalità extra.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "Per il seguente testo, estrarre le seguenti informazioni:\n",
    "\n",
    "gift: l'articolo è stato acquistato come regalo per qualcun altro?\n",
    "Rispondi True se sì, False se no o sconosciuto.\n",
    "\n",
    "delivery_days: Quanti giorni sono passati prima che il prodotto\n",
    "arrivasse? Se queste informazioni non sono disponibili, output -1.\n",
    "\n",
    "price_value: Estrarre eventuali frasi sul valore o prezzo,\n",
    "e restituirle come una lista Python separata da virgole.\n",
    "\n",
    "Formattare l'output come JSON con le seguenti chiavi:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "testo: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template=\"Per il seguente testo, estrarre le seguenti informazioni:\\n\\ngift: l'articolo è stato acquistato come regalo per qualcun altro?\\nRispondi True se sì, False se no o sconosciuto.\\n\\ndelivery_days: Quanti giorni sono passati prima che il prodotto\\narrivasse? Se queste informazioni non sono disponibili, output -1.\\n\\nprice_value: Estrarre eventuali frasi sul valore o prezzo,\\ne restituirle come una lista Python separata da virgole.\\n\\nFormattare l'output come JSON con le seguenti chiavi:\\ngift\\ndelivery_days\\nprice_value\\n\\ntesto: {text}\\n\"))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\"leggermente più costoso\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# You will get an error by running this line of code \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# because'gift' is not a dictionary\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 'gift' is a string\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"L'articolo è stato acquistato come \\\n",
    "                             regalo per qualcun altro?\\\n",
    "                             Rispondi True se sì, False se no o sconosciuto.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"Quanti giorni sono passati\\\n",
    "                                      prima che il prodotto arrivasse? Se queste\\\n",
    "                                      informazioni non sono disponibili, restituisci -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Estrai qualsiasi frase riguardante\\\n",
    "                                          il valore o il prezzo e restituiscile come\\\n",
    "                                          lista Python separata da virgole.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // L'articolo è stato acquistato come                              regalo per qualcun altro?                             Rispondi True se sì, False se no o sconosciuto.\n",
      "\t\"delivery_days\": string  // Quanti giorni sono passati                                      prima che il prodotto arrivasse? Se queste                                      informazioni non sono disponibili, restituisci -1.\n",
      "\t\"price_value\": string  // Estrai qualsiasi frase riguardante                                          il valore o il prezzo e restituiscile come                                          lista Python separata da virgole.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "Per il seguente testo, estrarre le seguenti informazioni:\n",
    "regalo: L'articolo è stato acquistato come regalo per qualcun altro? \n",
    "Rispondi True se sì, False se no o sconosciuto.\n",
    "giorni_di_consegna: Quanti giorni sono passati prima che il prodotto arrivasse? \n",
    "Se queste informazioni non sono disponibili, restituisci -1.\n",
    "valore_prezzo: Estrarre qualsiasi frase riguardante il valore \n",
    "o il prezzo e restituirla come lista Python separata da virgole.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per il seguente testo, estrarre le seguenti informazioni:\n",
      "regalo: L'articolo è stato acquistato come regalo per qualcun altro? \n",
      "Rispondi True se sì, False se no o sconosciuto.\n",
      "giorni_di_consegna: Quanti giorni sono passati prima che il prodotto arrivasse? \n",
      "Se queste informazioni non sono disponibili, restituisci -1.\n",
      "valore_prezzo: Estrarre qualsiasi frase riguardante il valore \n",
      "o il prezzo e restituirla come lista Python separata da virgole.\n",
      "\n",
      "text: Questo soffiatore di foglie è davvero sorprendente. Ha quattro impostazioni: soffiatore per candele,\n",
      "brezza leggera, città ventosa e tornado. È arrivato in due giorni, proprio in tempo per il regalo di\n",
      "anniversario di mia moglie. Penso che mia moglie lo abbia apprezzato così tanto che è rimasta \n",
      "senza parole. Finora sono stato l'unico a usarlo, e lo uso ogni altro mattino per togliere le \n",
      "foglie dal nostro prato. È leggermente più costoso degli altri soffiatori di foglie sul mercato, \n",
      "ma penso che valga la pena per le funzionalità extra.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // L'articolo è stato acquistato come                              regalo per qualcun altro?                             Rispondi True se sì, False se no o sconosciuto.\n",
      "\t\"delivery_days\": string  // Quanti giorni sono passati                                      prima che il prodotto arrivasse? Se queste                                      informazioni non sono disponibili, restituisci -1.\n",
      "\t\"price_value\": string  // Estrai qualsiasi frase riguardante                                          il valore o il prezzo e restituiscile come                                          lista Python separata da virgole.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": true, \n",
      "\t\"delivery_days\": 2, \n",
      "\t\"price_value\": \"È leggermente più costoso degli altri soffiatori di foglie sul mercato, ma penso che valga la pena per le funzionalità extra.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': 2,\n",
       " 'price_value': 'È leggermente più costoso degli altri soffiatori di foglie sul mercato, ma penso che valga la pena per le funzionalità extra.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Given the following text source :\n",
    "\" \n",
    "Affitto casa in zona Crocetta per soli studenti. L'appartamento è ben collegato con i mezzi pubblici\n",
    "e dista solo 15min dal Politecnico di Torino. Il \n",
    "\"\n",
    "\n",
    "- Create an istance of the class ChatOpenAI and configure the model so that it will use the model gpt-4.0 with a temperature of 0.1.\n",
    "- Create an Output parser for the following schema\n",
    "```json\n",
    "\t{\n",
    "\t\t\"\": true, \n",
    "\t\t\"delivery_days\": 2, \n",
    "\t\t\"price_value\": \"È leggermente più costoso degli altri soffiatori di foglie sul mercato, ma penso che valga la pena per le funzionalità extra.\"\n",
    "\t}\n",
    "```\n",
    "- Create an istance of the class Prompt Template \n",
    "- Use the output of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
