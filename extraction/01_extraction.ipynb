{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "During this presentation, we will explore an interactive notebook that shows how to develop and use some functionality in Python to optimize the analysis of contract documents.\n",
    "\n",
    "## Purpose of the Demo\n",
    "Our main goal is to illustrate how preprocessing, chunkization, and information extraction functions can simplify the processing and extraction of data from a database of contract documents. We will show how to use these techniques to automate, with potential to go as far as improving the efficiency and accuracy of contract analysis.\n",
    "\n",
    "## Preprocessing\n",
    "Initially, thinking of real world documents, derived from OCR, a major preprocessing phase of contract documents would be required. This is essential to clean and prepare the contract texts for later analysis. Some of the different preprocessing operations that can be applied are the removal of punctuation, stopwords, and lemmatization of terms. This can have a strong impact and help to improve the quality of information extraction.\\\n",
    "In our specific case, however, these operations are both uninteresting and unhelpful: we take documents from an already clean and preprocessed dataset, and using LLM as GPT with large natural language processing capabilities tends to prefer complete texts rather than e.g., without stopwords.\n",
    "\n",
    "## Chunkization\n",
    "A key step is chunkization, which involves dividing the contract text into bite-sized blocks of text. As we will explain, although GPT is capable of processing increasingly large windows of text, it will always be necessary to split the text and process it in blocks. We will build an advanced method based on tokenization and semantic segmentation that identifies and keeps sentences intact, in mood so that important information is not lost.\n",
    "\n",
    "## Information Extraction\n",
    "We will then address the core, which is the extraction of information from contract documents. Requests to GPT may require techniques such as prompt-engineering and other filters and optimizations, but for the purposes of this demo we will extract naively and try to understand how to then process the results. We will place attention on the reliability and accuracy of information extraction, and how the combined use of preprocessing and chunkization functions can affect the final results.\n",
    "\n",
    "## Postprocessing\n",
    "Finally, we will aggregate the results of the extractions from the various chunks of contract documents. During the postprocessing phase, it is critical to aggregate and filter the extracted results by merging, merging, or combining the results extracted from the individual chunks, allowing for sensible and consistent answers to the questions posed about the content.\\\n",
    "Somewhat complex merging, semantic prioritization, and majority logic can be implemented at this stage, but for now we will keep the approach simple and functional, with rules that are easily understood and evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
