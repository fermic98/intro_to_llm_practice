{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REQUIRED DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  \\\n",
    "    \"langchain>=0.0.350\" \\\n",
    "    \"transformers>=4.24,<5\" \\\n",
    "    sqlalchemy -U \\\n",
    "    \"faiss-cpu>=1.7,<2\" \\\n",
    "    \"pypdf>=3.8,<4\" \\\n",
    "    pinecone-client==2.2.4 \\\n",
    "    apache-beam==2.52. \\\n",
    "    tiktoken==0.5.2 \\\n",
    "    \"ipywidgets>=7,<8\" \\\n",
    "    matplotlib==3.8.2 \\\n",
    "    anthropic==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESTART THE KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT BEDROCK CLIENT\n",
    "\n",
    "Establishing a connection to the Berock service using AWS credentials and configuration settings provided through environment variables. This allows the Python script to interact with the Bedrock service using the boto3_bedrock object, which serves as a client for making API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET UP THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "    inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                        \"temperature\":0.5,\n",
    "                        \"top_k\":250,\n",
    "                        \"top_p\":1,\n",
    "                        \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                        }\n",
    "\n",
    "    textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                        client = boto3_bedrock, \n",
    "                        model_kwargs = inference_modifier \n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting engineering\n",
    "Prompting engineerins is the process of designing prompts in a way that optimizes the performance of large language models (LLMs) for specific tasks.\n",
    "In this practice we are going to use the following prompting techniques :\n",
    "- Zero-shot\n",
    "- Few-shot\n",
    "- COT\n",
    "\n",
    "## Zero-shot prompt templates\n",
    "Zero-shot prompt engineering involves crafting prompts for language models to enable them to perform tasks without explicit training examples or fine-tuning on that specific task, leveraging their initial training.\n",
    "\n",
    "Large language models (LLMs) excel at various tasks out of the box:\n",
    "- Text Generation: Generating text in a specific style or genre without fine-tuning on a large corpus of text in that style.\n",
    "- Text Classification: Classifying text into predefined categories without explicit training examples for each category.\n",
    "- Question Answering: Answering questions based on general knowledge without task-specific training data.\n",
    "- Language Translation: Translating text between languages without training data for specific language pairs.\n",
    "- Summarization: Generating summaries of text documents without task-specific training on summarization datasets.\n",
    "- Sentiment Analysis: Analyzing the sentiment of text without labeled examples for each sentiment class.\n",
    "\n",
    "Today's large LLMs, such as GPT-3.5, are finely tuned to follow instructions and are trained on vast amounts of data, making them capable of performing various tasks \"zero-shot.\"\n",
    "\n",
    "Here is one example of the Zero-shot techniques used for Sentiment Analysis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classify the text into neutral, negative or positive. \n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the prompt above we didn't provide the model with any examples of text alongside their classifications, the LLM already understands \"sentiment\" -- that's the zero-shot capabilities at work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises :\n",
    "Try to solve the following problem using the Zero-shot techniques :\n",
    "\n",
    "#### Exercise 1 - Text Summarization:\n",
    "One of the standard tasks in natural language generation is text summarization. Text summarization can include many different flavors and domains. In fact, one of the most promising applications of language models is the ability to summarize articles and concepts into quick and easy-to-read summaries. Let's try a basic summarization task using prompts.\n",
    "\n",
    "Let's say you are interested to learn about antibiotics.\n",
    "\n",
    "Start by requesting an explanation of antibiotics from the model.\n",
    "Then, ask the model to provide a concise summary of the definition it provided earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the definition of antibiotics\n",
    "prompt = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "antibiotics_definition = textgen_llm(prompt)\n",
    "\n",
    "#Summarize the definition of antibiotics\n",
    "prompt_2 = antibiotics_definition + \"...\"\n",
    "summary = textgen_llm(prompt_2)\n",
    "\n",
    "print_ww(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 - Code generation :\n",
    "One application where LLMs are quite effective is code generation. Copilot is a great example of this. There are a vast number of code-generation tasks you can perform with clever prompts.\n",
    "\n",
    "Imagine you're conducting an analysis across various departments within the university.\n",
    "You need to extract the studentsID and the students names of the computer science department.\n",
    "\n",
    "Provide info about possible database tables the model should use in the query.\n",
    "Then ask the model to generate a valid MySQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the definition of antibiotics\n",
    "prompt = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "SQL_query = textgen_llm(prompt)\n",
    "\n",
    "print_ww(SQL_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot prompt templates\n",
    "While large-language models demonstrate remarkable zero-shot capabilities, they still fall short on more complex tasks when using the zero-shot setting. Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\n",
    "\n",
    "Giving Claude examples of how you want it to behave (or how you want it not to behave) is extremely effective for:\n",
    "- Getting the right answer\n",
    "- Getting the answer in the right format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 - Model behaviour\n",
    "Pretend you're a developer trying to build a \"parent bot\" that responds to questions from kids. Claude's default response is quite formal and robotic. This is going to break a child's heart.\n",
    "\n",
    "You could take the time to describe your desired tone, but it's much easier just to give Claude a few examples of ideal responses.\n",
    "\n",
    "Try to improve the answer of the model using the Few Shot Prompting technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-working solution with Few-shot technique\n",
    "prompt = \"\"\"\n",
    "User: Will Santa bring me presents on Christmas?\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Formatting\n",
    "\n",
    "In the following formatting example, we could walk Claude step by step through a set of formatting instructions on how to extract names and professions and then format them exactly the way we want, or we could just provide Claude with some correctly-formatted examples and Claude can extrapolate from there.\n",
    "\n",
    "The format in which we want to extract names and professions is like the following example :\n",
    "\n",
    "\"\n",
    "Narrative\n",
    "\"\n",
    "\n",
    "<individuals>\n",
    "1. Dr. Liam Patel [NEUROSURGEON]\n",
    "2. Olivia Chen [ARCHITECT]\n",
    "3. Ethan Kovacs [MISICIAN AND COMPOSER]\n",
    "4. Isabella Torres [CHEF]\n",
    "</individuals>\n",
    "\n",
    "To solve this exercise we need different narratives that highlight the professional contributions of some people. Let's ask to ChatGPT to provide this type of narrative always using the FEW SHOT prompting technique.\n",
    "Provide at least 2 or 3 example to teach the model the exact format you want to receive in the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-working solution with Few-shot technique\n",
    "prompt = \"\"\"\n",
    "Oak Valley, a charming small town, is home to a remarkable trio of individuals whose skills and dedication have left a lasting impact on the community.\n",
    "At the town's bustling farmer's market, you'll find Laura Simmons, a passionate organic farmer known for her delicious and sustainably grown produce. Her dedication to promoting healthy eating has inspired the town to embrace a more eco-conscious lifestyle.\n",
    "In Oak Valley's community center, Kevin Alvarez, a skilled dance instructor, has brought the joy of movement to people of all ages. His inclusive dance classes have fostered a sense of unity and self-expression among residents, enriching the local arts scene.\n",
    "Lastly, Rachel O'Connor, a tireless volunteer, dedicates her time to various charitable initiatives. Her commitment to improving the lives of others has been instrumental in creating a strong sense of community within Oak Valley.\n",
    "Through their unique talents and unwavering dedication, Laura, Kevin, and Rachel have woven themselves into the fabric of Oak Valley, helping to create a vibrant and thriving small town.\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm.invoke(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COT : Chain of thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduced in [Wei et al. (2022)](https://arxiv.org/abs/2201.11903), chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 - Sarcasm :\n",
    "The next exercise present a prompt in which is asked the model to analyze the sentiment of a film review. It's not easy to detect because the user used sarcasm in its review.\n",
    "\n",
    "Run the model with the given prompt to observe the answer and then try to improve it by using the COT technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example with Few-shot prompting\n",
    "prompt = \"\"\"\n",
    "User: Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. \n",
    "In totally unrelated news, I have been living under a rock since the year 1900.\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 - Dates :\n",
    "\n",
    "Change the prompt with COT technique and try to make the model answer correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "User: Name a famous movie starring an actor who was born in the year 1956.\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot COT : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One recent idea that came out more recently is the idea of zero-shot CoT [(Kojima et al. 2022)]() that essentially involves adding \"Let's think step by step\" to the original prompt. Let's try a simple problem and see how the model performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt with Zero-shot COT\n",
    "prompt = \"\"\"\n",
    "I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "                                    SEE BELOW FOR EXERCISES SOLUTIONS\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTIONS\n",
    "\n",
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "\n",
    "#Get the definition of antibiotics\n",
    "prompt = \"\"\"\n",
    "\"Explain antibiotics\\n\"\n",
    "\"A:\"\n",
    "\"\"\"\n",
    "\n",
    "antibiotics_definition = textgen_llm(prompt)\n",
    "\n",
    "#Summarize the definition of antibiotics\n",
    "prompt_2 = antibiotics_definition + \"\\nExplain the above text in one sentence :\"\n",
    "summary = textgen_llm(prompt_2)\n",
    "\n",
    "print_ww(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exercise 2\n",
    "\n",
    "#Get the definition of antibiotics\n",
    "prompt = \"\"\"\n",
    "    Table departments, columns = [DepartmentId, DepartmentName]\n",
    "    Table students, columns = [DepartmentId, StudentId, StudentName]\n",
    "    Create a MySQL query for all students in the Computer Science Department\n",
    "    \"\"\"\n",
    "\n",
    "SQL_query = textgen_llm(prompt)\n",
    "\n",
    "print_ww(SQL_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exercise 1\n",
    "#Solution with Few-shot technique\n",
    "prompt = \"\"\"\n",
    "User: Please complete the conversation by writing the next line, speaking as \"A\".\n",
    "Q: Is the tooth fairy real?\n",
    "A: Of course, sweetie. Wrap up your tooth and put it under your pillow tonight. \n",
    "There might be something waiting for you in the morning.\n",
    "Q: Will Santa bring me presents on Christmas?\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exercise 2\n",
    "#Solution with Few-shot technique\n",
    "prompt = \"\"\"\n",
    "User: In the bustling town of Emerald Hills, a diverse group of individuals made their\n",
    "mark. Sarah Martinez, a dedicated nurse, was known for her compassionate care\n",
    "at the local hospital.\n",
    "David Thompson, an innovative software engineer, worked tirelessly on groundbreaking\n",
    "projects that would revolutionize the tech industry.\n",
    "Meanwhile, Emily Nakamura, a talented artist and muralist, painted vibrant and thought-provoking\n",
    "pieces that adorned the walls of buildings and galleries alike. \n",
    "Lastly, Michael O'Connell, an ambitious entrepreneur, opened a unique, eco-friendly cafe that quickly\n",
    "became the town's favorite meeting spot.\n",
    "Each of these individuals contributed to the rich tapestry of the Emerald Hills community.\n",
    "<individuals>\n",
    "1. Sarah Martinez [NURSE]\n",
    "2. David Thompson [SOFTWARE ENGINEER]\n",
    "3. Emily Nakamura [ARTIST]\n",
    "4. Michael O'Connell [ENTREPRENEUR]\n",
    "</individuals>\n",
    "\n",
    "At the heart of the town, Chef Oliver Hamilton has transformed the culinary scene with his \n",
    "farm-to-table restaurant, Green Plate. Oliver's dedication to sourcing local, organic ingredients\n",
    "has earned the establishment rave reviews from food critics and locals alike.\n",
    "Just down the street, you'll find the Riverside Grove Library, where head librarian Elizabeth Chen\n",
    "has worked diligently to create a welcoming and inclusive space for all. Her efforts to expand\n",
    "the library's offerings and establish reading programs for children have had a significant \n",
    "impact on the town's literacy rates.\n",
    "As you stroll through the charming town square, you'll be captivated by the beautiful\n",
    "murals adorning the walls. These masterpieces are the work of renowned artist, Isabella Torres,\n",
    "whose talent for capturing the essence of Riverside Grove has brought the town to life.\n",
    "Riverside Grove's athletic achievements are also worth noting, thanks to former Olympic \n",
    "swimmer-turned-coach, Marcus Jenkins. Marcus has used his experience and passion to train \n",
    "the town's youth, leading the Riverside Grove Swim Team to several regional championships.\n",
    "<individuals>\n",
    "1. Oliver Hamilton [CHEF]\n",
    "2. Elizabeth Chen [LIBRARIAN]\n",
    "3. Isabella Torres [ARTIST]\n",
    "4. Marcus Jenkins [COACH]\n",
    "</individuals>\n",
    "\n",
    "Oak Valley, a charming small town, is home to a remarkable trio of individuals whose skills and \n",
    "dedication have left a lasting impact on the community.\n",
    "At the town's bustling farmer's market, you'll find Laura Simmons, a passionate organic farmer \n",
    "known for her delicious and sustainably grown produce. Her dedication to promoting healthy eating\n",
    "has inspired the town to embrace a more eco-conscious lifestyle.\n",
    "In Oak Valley's community center, Kevin Alvarez, a skilled dance instructor, has brought the joy\n",
    "of movement to people of all ages. His inclusive dance classes have fostered a sense of unity and\n",
    "self-expression among residents, enriching the local arts scene.\n",
    "Lastly, Rachel O'Connor, a tireless volunteer, dedicates her time to various charitable initiatives.\n",
    "Her commitment to improving the lives of others has been instrumental in creating a strong sense\n",
    "of community within Oak Valley.\n",
    "Through their unique talents and unwavering dedication, Laura, Kevin, and Rachel have woven\n",
    "themselves into the fabric of Oak Valley, helping to create a vibrant and thriving small town.\n",
    "Assistant: <individuals>\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm.invoke(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COT - Chain of thaugths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exercise 1\n",
    "\n",
    "#Example with Few-shot prompting\n",
    "prompt = \"\"\"\n",
    "User: Is this review sentiment positive or negative? \n",
    "Reason step by step firstly analyzing the positive side and then the negative one\n",
    "\n",
    "This movie blew my mind with its freshness and originality. \n",
    "In totally unrelated news, I have been living under a rock since 1900.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = textgen_llm.invoke(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 2\n",
    "prompt = \"\"\"\n",
    "User: Name a famous movie starring an actor who was born in the year 1956. \n",
    "First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\n",
    "\"\"\"\n",
    "\n",
    "response = textgen_llm.invoke(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
